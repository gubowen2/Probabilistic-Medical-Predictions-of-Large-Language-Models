{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466fdc63-5829-45d3-a09e-2d010ec4f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import copy\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28dccd-5b7c-4685-a7d5-4fa9e7f87136",
   "metadata": {},
   "source": [
    "### Download the MMLU datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848c0e3-b36a-42ce-8c2a-0602b4a89982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the datasets from HuggingFace\n",
    "#clinical_knowledge = load_dataset(\"cais/mmlu\", \"clinical_knowledge\")\n",
    "#college_medicine = load_dataset(\"cais/mmlu\", \"college_medicine\")\n",
    "\n",
    "anatomy = load_dataset(\"cais/mmlu\", \"anatomy\")\n",
    "college_biology = load_dataset(\"cais/mmlu\", \"college_biology\")\n",
    "medical_genetics = load_dataset(\"cais/mmlu\", \"medical_genetics\")\n",
    "professional_medicine = load_dataset(\"cais/mmlu\", \"professional_medicine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed251f-65fe-4f50-842e-f8f1c4819927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "#clinical_knowledge = load_dataset(\"../.cache/huggingface/datasets/cais___mmlu/clinical_knowledge\")\n",
    "#college_medicine = load_dataset(\"../.cache/huggingface/datasets/cais___mmlu/college_medicine\")\n",
    "\n",
    "anatomy = load_dataset(\"../.cache/huggingface/datasets/cais___mmlu/anatomy\")\n",
    "college_biology = load_dataset(\"../.cache/huggingface/datasets/cais___mmlu/college_biology\")\n",
    "medical_genetics = load_dataset(\"../.cache/huggingface/datasets/cais___mmlu/medical_genetics\")\n",
    "professional_medicine = load_dataset(\"../.cache/huggingface/datasets/cais___mmlu/professional_medicine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1fa2d8-5e0a-4f9b-9190-2ace4d823e50",
   "metadata": {},
   "source": [
    "### Add the processed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6cc59-e7d4-4e0b-9fe6-6b92f80c64cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each subset and save as CSV\n",
    "def process_and_save_subset(subset, filename):\n",
    "    test = pd.DataFrame(subset['test'])\n",
    "    validation = pd.DataFrame(subset['validation'])\n",
    "    dataset_list = [test, validation]\n",
    "    section_dict = {0: 'test', 1: 'validation'}\n",
    "    for i, dataset in enumerate(dataset_list):\n",
    "        dataset['section'] = [section_dict[i]] * len(dataset)\n",
    "    df = pd.concat(dataset_list, ignore_index=True)\n",
    "    df['correct_answer_str'] = df.apply(lambda row: row['choices'][row['answer']], axis=1)\n",
    "    df['wrong_answer_str_1'] = df.apply(lambda row: row['choices'][1] if row['answer'] == 0 else row['choices'][0], axis=1)\n",
    "    df['wrong_answer_str_2'] = df.apply(lambda row: row['choices'][2] if row['answer'] == 0 or row['answer'] == 1 else row['choices'][1], axis=1)\n",
    "    df['wrong_answer_str_3'] = df.apply(lambda row: row['choices'][2] if row['answer'] == 3 else row['choices'][3], axis=1)\n",
    "\n",
    "    # Split data into two groups and assign propose_correct_answer and proposed_answer\n",
    "    np.random.seed(42)\n",
    "    half_size = len(df) // 2\n",
    "    propose_correct = np.zeros(len(df))\n",
    "    propose_correct[:half_size] = 1\n",
    "    np.random.shuffle(propose_correct)  # Randomly shuffle the array to assign 1s and 0s\n",
    "\n",
    "    df['propose_correct_answer'] = propose_correct\n",
    "    df['proposed_answer'] = df.apply(lambda row: row['correct_answer_str'] if row['propose_correct_answer'] == 1 else np.random.choice([row['wrong_answer_str_1'], row['wrong_answer_str_2'], row['wrong_answer_str_3']]), axis=1)\n",
    "    \n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c712fbb2-b069-4266-8d50-aac309624651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and save both subsets\n",
    "#process_and_save_subset(clinical_knowledge, 'clinical_knowledge.csv')\n",
    "#process_and_save_subset(college_medicine, 'college_medicine.csv')\n",
    "\n",
    "process_and_save_subset(anatomy, 'anatomy.csv')\n",
    "process_and_save_subset(college_biology, 'college_biology.csv')\n",
    "process_and_save_subset(medical_genetics, 'medical_genetics.csv')\n",
    "process_and_save_subset(professional_medicine, 'professional_medicine.csv')\n",
    "\n",
    "print(\"Datasets processed and saved as CSV files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca738ab-a4ca-4e15-a608-763b18805743",
   "metadata": {},
   "source": [
    "### Download the MedQA datasets"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88e8286f-d1a1-4be4-9323-70a032c21188",
   "metadata": {},
   "source": [
    "# Download the datasets from HuggingFace\n",
    "medQA_en = load_dataset(\"bigbio/med_qa\", \"med_qa_en_source\")\n",
    "medQA_zh = load_dataset(\"bigbio/med_qa\", \"med_qa_zh_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a111fe-e455-4f32-b818-247fb07aac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "medQA_en = load_dataset(\"../.cache/huggingface/datasets/bigbio___med_qa/med_qa_en_source\")\n",
    "medQA_zh = load_dataset(\"../.cache/huggingface/datasets/bigbio___med_qa/med_qa_zh_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a6f6c9-6c6e-42ed-9667-ba9a3f1e0ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each subset and save as CSV\n",
    "def process_and_save_subset(dataframe, filename):\n",
    "    test = pd.DataFrame(dataframe['test'])\n",
    "    validation = pd.DataFrame(dataframe['validation'])\n",
    "    train = pd.DataFrame(dataframe['train'])\n",
    "    dataset_list = [test, validation, train]\n",
    "    section_dict = {0: 'test', 1: 'validation', 2: 'train'}\n",
    "    for i, dataset in enumerate(dataset_list):\n",
    "        dataset['section'] = [section_dict[i]] * len(dataset)\n",
    "    df = pd.concat(dataset_list, ignore_index=True)\n",
    "    df['correct_answer_str'] = df.apply(lambda row: row['answer'], axis=1)\n",
    "    df['wrong_answer_str_1'] = df.apply(lambda row: row['options'][1]['value'] if row['answer_idx'] == 'A' else row['options'][0]['value'], axis=1)\n",
    "    df['wrong_answer_str_2'] = df.apply(lambda row: row['options'][2]['value'] if row['answer_idx'] == 'A' or row['answer_idx'] == 'B' else row['options'][1]['value'], axis=1)\n",
    "    df['wrong_answer_str_3'] = df.apply(lambda row: row['options'][2]['value'] if row['answer_idx'] == 'D' or row['answer_idx'] == 'E' else row['options'][3]['value'], axis=1)\n",
    "    df['wrong_answer_str_4'] = df.apply(lambda row: row['options'][3]['value'] if row['answer_idx'] == 'E' else row['options'][4]['value'], axis=1)\n",
    "\n",
    "    # Split data into two groups and assign propose_correct_answer and proposed_answer\n",
    "    np.random.seed(42)\n",
    "    half_size = len(df) // 2\n",
    "    propose_correct = np.zeros(len(df))\n",
    "    propose_correct[:half_size] = 1\n",
    "    np.random.shuffle(propose_correct)  # Randomly shuffle the array to assign 1s and 0s\n",
    "\n",
    "    df['propose_correct_answer'] = propose_correct\n",
    "    df['proposed_answer'] = df.apply(lambda row: row['correct_answer_str'] if row['propose_correct_answer'] == 1 else np.random.choice([row['wrong_answer_str_1'], row['wrong_answer_str_2'], row['wrong_answer_str_3'], row['wrong_answer_str_4']]), axis=1)\n",
    "    \n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02695ed3-c001-4db1-9c47-4c2f2bb41b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and save both subsets\n",
    "#process_and_save_subset(medQA_en, 'medQA_en.csv')\n",
    "#process_and_save_subset(medQA_zh, 'medQA_zh.csv')\n",
    "\n",
    "process_and_save_subset(medQA_en, 'USMLE.csv')\n",
    "#process_and_save_subset(medQA_zh, 'MCMLE.csv')\n",
    "\n",
    "print(\"Datasets processed and saved as CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5822b136-1e26-458f-89de-364cd0f40242",
   "metadata": {},
   "outputs": [],
   "source": [
    "medQA_en_df = pd.read_csv('USMLE.csv')\n",
    "medQA_en_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc4132fa-5cfa-402c-a930-dfd08561f067",
   "metadata": {},
   "source": [
    "medQA_zh_df = pd.read_csv('MCMLE.csv')\n",
    "medQA_zh_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beae353-6514-4537-ab7d-842e6b2671c1",
   "metadata": {},
   "source": [
    "### Process the SDoH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892c4cb-7888-4416-a5c4-b1d7c53ea745",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices_dict = {\"SDoH_Q1\": [\"Single\", \"Widowed\", \"Divorced\", \"Married\", \"Not mentioned\"],\n",
    "                \"SDoH_Q2\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5 or more\", \"Not mentioned\"],\n",
    "                \"SDoH_Q3\": [\"Yes\", \"No\", \"Not mentioned\"],\n",
    "                \"SDoH_Q4\": [\"Yes\", \"No\", \"Not mentioned\"],\n",
    "                \"SDoH_Q5\": [\"Yes\", \"No\", \"Not mentioned\"],\n",
    "                \"SDoH_Q6\": [\"Yes\", \"No\", \"Not mentioned\"],\n",
    "                \"SDoH_Q7\": [\"Employed\", \"Jobless\", \"Retired\", \"Not mentioned\"],\n",
    "                \"SDoH_Q8\": [\"Elementary school\", \"Middle school\", \"High school\", \"College\", \"Graduate School\", \"Not mentioned\"],\n",
    "                \"SDoH_Q9\": [\"Yes\", \"No\", \"In the past\", \"Not mentioned\"]}\n",
    "\n",
    "def process_and_save_subset(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    assert len(df) == 200, \"The length of the SDoH CSV files must be 200\"\n",
    "    choices_list = choices_dict[filename.split(\".\")[0]]\n",
    "    df['choices'] = [choices_list] * len(df)\n",
    "    df['question'] = df.apply(lambda row: f\"Given the following context about a patient's socioeconomic document:\\n{row['Text']}\\n{row['Raw Question']}\", axis=1)\n",
    "    df['wrong_choices'] = df.apply(lambda row: [element for element in row['choices'] if element != row['correct_answer_str']], axis=1)\n",
    "    for i in range(0, len(choices_list) - 1):\n",
    "        df[f'wrong_answer_str_{i}'] = df.apply(lambda row: row['wrong_choices'][i], axis=1)\n",
    "\n",
    "    # Split data into two groups and assign propose_correct_answer and proposed_answer\n",
    "    np.random.seed(42)\n",
    "    half_size = len(df) // 2\n",
    "    propose_correct = np.zeros(len(df))\n",
    "    propose_correct[:half_size] = 1\n",
    "    np.random.shuffle(propose_correct)  # Randomly shuffle the array to assign 1s and 0s\n",
    "\n",
    "    df['propose_correct_answer'] = propose_correct\n",
    "    df['proposed_answer'] = df.apply(lambda row: row['correct_answer_str'] if row['propose_correct_answer'] == 1 else np.random.choice(row['wrong_choices']), axis=1)\n",
    "    \n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ce0b7af-601e-4ee7-bf8f-f1919c6670b1",
   "metadata": {},
   "source": [
    "# Process and save both subsets\n",
    "for i in range(1, 10):\n",
    "    process_and_save_subset(f'SDoH_Q{i}.csv')\n",
    "\n",
    "print(\"Datasets processed and saved as CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c6111-5d5b-49d3-9712-236180d3106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(filenames):\n",
    "    # List to hold DataFrames\n",
    "    dfs = []\n",
    "    \n",
    "    # Loop through the CSV files\n",
    "    for file in filenames:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Select the specified columns\n",
    "        selected_columns = df[['question', 'correct_answer_str', 'choices', 'propose_correct_answer', 'proposed_answer']]\n",
    "        \n",
    "        # Append the selected columns DataFrame to the list\n",
    "        dfs.append(selected_columns)\n",
    "    \n",
    "    # Concatenate all DataFrames\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Save the concatenated DataFrame to \"SDoH.csv\"\n",
    "    concatenated_df.to_csv('SDoH.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22e80e1d-1887-4f8e-9437-b33210d04115",
   "metadata": {},
   "source": [
    "filenames = [f\"SDoH_Q{i}.csv\" for i in range(1, 10)]\n",
    "combine(filenames)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96c7f2b5-f767-4c8e-9e3a-5ffd9cc44b21",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"SDoH.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2234003-6368-45b7-ba23-f57269917c8e",
   "metadata": {},
   "source": [
    "### Add the A/B choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a82ad2-8569-47a2-add1-2d028116faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_A_B_choices(filename):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # Set the seed to ensure reproducibility\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Add the 'correct_choice' column with random 'A' or 'B'\n",
    "    df['correct_choice'] = np.random.choice(['A', 'B'], size=len(df))\n",
    "    \n",
    "    # Initialize the 'choice_A_str' and 'choice_B_str' columns\n",
    "    df['choice_A_str'] = ''\n",
    "    df['choice_B_str'] = ''\n",
    "    \n",
    "    # Iterate over each row to set 'choice_A_str' and 'choice_B_str' based on 'correct_choice'\n",
    "    for index, row in df.iterrows():\n",
    "        wrong_answers = [row[col] for col in df.columns if col.startswith('wrong_answer_str_')]\n",
    "        \n",
    "        if row['correct_choice'] == 'A':\n",
    "            df.at[index, 'choice_A_str'] = row['correct_answer_str']\n",
    "            df.at[index, 'choice_B_str'] = np.random.choice(wrong_answers)\n",
    "        else:\n",
    "            df.at[index, 'choice_B_str'] = row['correct_answer_str']\n",
    "            df.at[index, 'choice_A_str'] = np.random.choice(wrong_answers)\n",
    "\n",
    "    df['correct_choice_id'] = df.apply(lambda row: 1 if row['correct_choice'] == 'A' else 0, axis=1)\n",
    "    # Save the modified DataFrame back to the CSV file\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05f809-f880-43b5-9760-05cc04e1603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_A_B_choices_SDoH(filename):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # Set the seed to ensure reproducibility\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Add the 'correct_choice' column with random 'A' or 'B'\n",
    "    df['correct_choice'] = np.random.choice(['A', 'B'], size=len(df))\n",
    "    \n",
    "    # Initialize the 'choice_A_str' and 'choice_B_str' columns\n",
    "    df['choice_A_str'] = ''\n",
    "    df['choice_B_str'] = ''\n",
    "    \n",
    "    # Iterate over each row to set 'choice_A_str' and 'choice_B_str' based on 'correct_choice'\n",
    "    for index, row in df.iterrows():\n",
    "        choices = ast.literal_eval(row['choices'])\n",
    "        incorrect_choices = [choice for choice in choices if choice != row['correct_answer_str']]\n",
    "        \n",
    "        if row['correct_choice'] == 'A':\n",
    "            df.at[index, 'choice_A_str'] = row['correct_answer_str']\n",
    "            df.at[index, 'choice_B_str'] = np.random.choice(incorrect_choices)\n",
    "        else:\n",
    "            df.at[index, 'choice_B_str'] = row['correct_answer_str']\n",
    "            df.at[index, 'choice_A_str'] = np.random.choice(incorrect_choices)\n",
    "\n",
    "    df['correct_choice_id'] = df.apply(lambda row: 1 if row['correct_choice'] == 'A' else 0, axis=1)\n",
    "    # Save the modified DataFrame back to the CSV file\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dddbaa3-fa89-4db9-9a86-0325442ed2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_A_B_choices('clinical_knowledge.csv')\n",
    "add_A_B_choices('college_medicine.csv')\n",
    "add_A_B_choices('medQA_en.csv')\n",
    "add_A_B_choices('medQA_zh.csv')\n",
    "for i in range(1, 10):\n",
    "    add_A_B_choices(f'SDoH_Q{i}.csv')\n",
    "add_A_B_choices_SDoH('SDoH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06a3a5-1291-440f-8ada-2f80d6a9082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_A_B_choices('anatomy.csv')\n",
    "add_A_B_choices('college_biology.csv')\n",
    "add_A_B_choices('medical_genetics.csv')\n",
    "add_A_B_choices('professional_medicine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531355d3-961f-4edb-92bd-5fe631df6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_A_B_choices('USMLE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dfb42a-5b74-4ef9-a135-9d71f57ca316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('anatomy.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8532f7-b123-47d3-a45e-5b2b0242a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('college_biology.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fead4e-cd33-4a1a-83e7-aa2d97a18cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('medical_genetics.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8c173-5183-49d7-a012-3591823a8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('professional_medicine.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6f2d8-bd57-42d9-ba9f-372dbdd9bec1",
   "metadata": {},
   "source": [
    "### Make imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c00d0b-6201-4661-8cfb-557fa3161ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight_correct_choices(filename, target_ratio):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Calculate the current ratio of choice A being correct\n",
    "    current_ratio = df['correct_choice'].value_counts(normalize=True)['A']\n",
    "    print(f\"Current ratio of A being correct: {current_ratio*100:.2f}%\")\n",
    "\n",
    "    # Determine the number of rows that need to be switched to achieve the target ratio\n",
    "    total_rows = len(df)\n",
    "    target_num_A = int(target_ratio * total_rows)\n",
    "    current_num_A = int(current_ratio * total_rows)\n",
    "    num_to_switch = abs(target_num_A - current_num_A)\n",
    "    \n",
    "    # Select rows to switch\n",
    "    if target_num_A > current_num_A:\n",
    "        # Need to increase A correct choices\n",
    "        rows_to_switch = df[df['correct_choice'] == 'B'].sample(num_to_switch, random_state=42).index\n",
    "    else:\n",
    "        # Need to increase B correct choices\n",
    "        rows_to_switch = df[df['correct_choice'] == 'A'].sample(num_to_switch, random_state=42).index\n",
    "\n",
    "    # Create new columns for the altered data\n",
    "    df[f'correct_choice ({target_ratio*100:.0f}%)'] = df['correct_choice']\n",
    "    df[f'choice_A_str ({target_ratio*100:.0f}%)'] = df['choice_A_str']\n",
    "    df[f'choice_B_str ({target_ratio*100:.0f}%)'] = df['choice_B_str']\n",
    "    df[f'correct_choice_id ({target_ratio*100:.0f}%)'] = df['correct_choice_id']\n",
    "\n",
    "    # Switch the choices for the selected rows\n",
    "    df.loc[rows_to_switch, f'correct_choice ({target_ratio*100:.0f}%)'] = df.loc[rows_to_switch, 'correct_choice'].apply(lambda x: 'A' if x == 'B' else 'B')\n",
    "    df.loc[rows_to_switch, f'choice_A_str ({target_ratio*100:.0f}%)'] = df.loc[rows_to_switch, 'choice_B_str']\n",
    "    df.loc[rows_to_switch, f'choice_B_str ({target_ratio*100:.0f}%)'] = df.loc[rows_to_switch, 'choice_A_str']\n",
    "    df.loc[rows_to_switch, f'correct_choice_id ({target_ratio*100:.0f}%)'] = df.loc[rows_to_switch, 'correct_choice_id'].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Successfully add imbalanced data into {filename}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa3fa4-e3aa-468f-811d-29ad28166027",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list = ['clinical_knowledge.csv', 'college_medicine.csv', 'medQA_en.csv', 'medQA_zh.csv', 'SDoH_Q1.csv', 'SDoH_Q2.csv', 'SDoH_Q3.csv', 'SDoH_Q4.csv', 'SDoH_Q5.csv', 'SDoH_Q6.csv', 'SDoH_Q7.csv', 'SDoH_Q8.csv', 'SDoH_Q9.csv', 'SDoH.csv']\n",
    "#target_ratio_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "target_ratio_list = [0.05]\n",
    "for filename in filename_list:\n",
    "    for target_ratio in target_ratio_list:\n",
    "        reweight_correct_choices(filename, target_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aac071-1bbb-4200-9620-f0540be3c9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
